% use PassOptionsToPackage before loading packages in template
\PassOptionsToPackage{hyphens}{url}

\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix2019_v3}

% to be able to draw some self-contained figs
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{caption}
\usepackage{cleveref}

\crefformat{section}{\S#2#1#3} % see manual of cleveref, section 8.2.1
\crefformat{subsection}{\S#2#1#3}
\crefformat{subsubsection}{\S#2#1#3}

\lstset{basicstyle=\ttfamily\footnotesize,breaklines=true}


\hypersetup{citecolor=black}

%-------------------------------------------------------------------------------
\begin{document}
%-------------------------------------------------------------------------------

%don't want date printed
\date{}

% make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large{\bf \textit{Paranoid}: Privacy through Granular Separation of User Identities}}

\author{
    {\rm Brandon Tan (tjiansin)}\\
    Brown University
    \and
    {\rm Irvin Lim (ilim5)}\\
    Brown University
}

\maketitle

\begin{abstract}
    Paranoid aims to allow users to regain control of their personal data. We explore a new paradigm of
    designing web services to present personal data on HTML webpages without having access to the data
    itself, with the assumption that the web service is untrusted. Paranoid achieves this by storing all
    personal data separately outside of the service, only substituting the private data on the client
    side via DOM manipulation using a Chromium extension, as well as a secure platform to share private
    data files with other users built on top of Keybase. We also show that such an approach is secure
    against various attack vectors, in the case of both malicious web services and users.
\end{abstract}

%-------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------

\subsection{Goals of the project}\label{sec:project_goals}

In the recent years, there have been an increasing number of high profile instances of users'
personal information being compromised via web services. This includes, but is not limited to:

\begin{enumerate}
    \item Data breaches arising from inadequate access control, e.g. Equifax announced a data
          breach in 2017 that exposed the personal information of over 140 million consumers
          worldwide \cite{OBrien:2017};
    \item Governments and law enforcement agencies that could potentially demand private
          corporations to hand over its users' personal information;
    \item Lack of consent for services to pass on users' personal information to external vendors,
          e.g. the Facebook/Cambridge Analytica scandal which resulted in 87 million users' Facebook
          profiles being acquired by Cambridge Analytica for voter targeting in the 2016 US
          election;
    \item Lack of guarantee for users' personal information being stored and processed securely by
          the service;
    \item Personal data acquired from multiple sources can be correlated to paint a comprehensive
          overview of a users' online identity.
\end{enumerate}

There have been various approaches in solving the above mentioned challenges, including information flow control (IFC) frameworks such as DStar \cite{Zeldovich:2008:SDS:1387589.1387610}, Resin \cite{Yip:2009:IAS:1629575.1629604} and Jacqueline \cite{Yang:2016:PDI:2980983.2908098}, which require implicit trust in the service itself to adequately implement these guarantees. Additionally, while services like Facebook are starting to provide fine-grained control over who should be allowed access to what data, it is complex to implement and potentially buggy, as exemplified with a recent Facebook bug that affected 14 million users \cite{Sheera:2018}.

A web service may commonly ingest private data during registration, through the means of single sign-on (SSO) mechanisms using widely used accounts like Facebook and Google. The wide proliferation of SSO means that a user's identity could potentially be tracked and pieced together over multiple web services, by correlating user accounts with the same email address.

As such, we aimed to design a system which allows a user to control precisely who should be granted access to their personal data, such that without having been granted access, the user's identity on the service should remain anonymous from their point of view. This means that private data should not be divulged to the web service, even during registration where personal information like email addresses are commonly used to create a user account. At the same time, we want the web service to still be able to work as though it had the data in the first place.

\begin{figure*}
    \centering
    \def\svgwidth{1.5\columnwidth}
    \input{svg/paranoid_architecture.pdf_tex}
    \caption{Main architecture of Paranoid}
    \label{fig:paranoid_architecture}
\end{figure*}

\subsection{Targeted services}

We classify web services into two distinct categories: \textit{data platforms} and \textit{data consumers}.

A data consumer is a web service that manipulates private user data, and requires the actual private data to be divulged to the service, which otherwise would fail to perform a critical function and be of no value to the user. One such example would be Equifax, which requires the user's actual name and social security number (SSN) in order to perform credit checks with credit bureaus and other financial institutions.

On the other hand, a data platform is a web service that serves user data to other users on the platform, and does not fail even if the data is hidden from the service. One such example would be social media sites like Facebook and Twitter, where the contents of a tweet can be completely transparent from the point of view of the service, but is only important to other users who view that tweet.

In this case, we will only be focusing on designing a system that can work on top of data platforms, since it would be pointless to come up with such a system for data consumers which require and expect input of true and accurate personal data.

Paranoid's key idea is thus to separate the presentation of the private user data from the contents of the data itself on these web services. Specifically, the HTML webpage returned by the web service should define the structure and appearance of the private data, while the private data is only substituted in the browser on the client side for users who have access rights to the data.

\section{Overview of Paranoid}

There are three main parts to our solution: 1) providing a public key-based authentication scheme that should be supported by a Paranoid-compliant service, 2) overlaying private data on top of a web page securely in a browser to users who have access to said private data, and 3) providing a means of defining which users have access to what pieces of data, as well as a storage and transport mechanism that will support it.

The main components of Paranoid is implemented as a Chromium browser extension, which would handle both authentication and overlaying of private data, as well as a daemon server, which the browser extension would communicate with in order to fetch and store data within the storage mechanism, as shown in Figure \ref{fig:paranoid_architecture}.

\subsection{Public key authentication}

Paranoid provides a single sign-on (SSO) mechanism, similar to how users can log in to third-party services using their Google or Facebook accounts via OAuth 2.0. However, instead of sharing private data such as email address, name, etc. during registration, a new \textit{service identity} is generated, which includes a private/public key pair. The public key portion is transmitted to the service, which stores it in order to authenticate the user for future logins. The web service returns a unique \textit{UID} for the user, which is equivalent to the user's anonymous identifier for the service.

User authentication for the service is done using a challenge-response authentication scheme, where the service provides a randomly generated nonce challenge encrypted using the provided public key, and the user must prove they can retrieve the original nonce value by decrypting it with the corresponding private key, as shown in Figure \ref{fig:paranoid_auth}. Once verified, the service can then provide a persistent session token, which is typically a cookie that allows a user to use it for subsequent authenticated requests.

\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{svg/paranoid_auth.pdf_tex}
    \caption{Registration and authentication flow in Paranoid using public keys.}
    \label{fig:paranoid_auth}
\end{figure}

We envision that Paranoid-compliant web services should support both existing login flows like email/password combinations or third-party SSO solutions, as well as to support the Paranoid authentication scheme using public key infrastructure (PKI). At the same time, web services should support a mix of both divulged data (i.e. data that was divulged to the service) as well as hidden data (i.e. data that should only be visible to other users through Paranoid).

\subsection{Private data overlay in the DOM}

A Paranoid user does not have any private data sent to the web service, and as such the service cannot display the private data values in the returned HTML webpage. We would require a Paranoid service to substitute the contents in the HTML elements with a custom \texttt{<paranoid>} HTML tag as a placeholder. By default, a custom HTML element is styled as an inline element, much like a \texttt{<span>} element, and we foresee that using this would not negatively affect the service's ability to style the placeholder element with normal CSS.

\begin{center}
    \begin{lstlisting}
    <paranoid uid="15" attribute="first_name">
      Hidden Content
    </paranoid>
    \end{lstlisting}
    \captionof{figure}{Example \texttt{<paranoid>} HTML tag.}
    \label{fig:paranoid_tag}
\end{center}

The \texttt{<paranoid>} tag can contain several attributes, but the most important ones are \texttt{uid}, which specifies the UID of the user that this placeholder tag is associated with, and \texttt{attribute}, which is a canonical name for the private data field that the placeholder is masking. Examples of field names include \texttt{first\_name} or \texttt{email}, or could even be custom defined on a per-service level. The body of the tag itself would typically be a placeholder value displayed if the user does not have the appropriate permissions to view the data value.

The browser extension can simply inspect the webpage for all such \texttt{<paranoid>} HTML tags, and replace the inner text of the tag with the data values by matching against the origin of the web page, and the UID and field name of the HTML tag. In other words, we associate the \textit{field tuple}, as defined by $\langle origin, uid, field\_name \rangle$, with a specific private data value, and the browser extension simply enumerates all available data values to find if its field tuple matches that on the \texttt{<paranoid>} HTML tag.

\subsection{Isolation using Shadow DOM}\label{sec:shadow_dom}

If we naively replace the HTML tags as a simple string replacement, the untrusted web service is able to extract the already-replaced HTML tags to retrieve the private information using client-side JavaScript. A notable example would be British Airways' data breach in 2018 \cite{Ng:2018}, where malicious client-side JavaScript that was injected to the British Airways website was able to siphon credit card information from users when forms were submitted.

Instead, we make use of the Shadow DOM specification \cite{Bidelman}, which is supported by most major browsers today. The Shadow DOM specification was developed for the purpose of the Web Component standard, which was designed as a tool to develop component-based (i.e. composition-based) web applications. For example, CSS defined within the shadow DOM would be locally scoped to the shadow DOM, preventing global selectors from affecting elements outside of the shadow DOM, and JavaScript element queries using \texttt{document.querySelector} (for example) would not return elements inside of shadow DOMs. This means that web developers can design components as standalone DOM trees which can be composed inside of other DOM trees without fear of polluting the global CSS and JS namespace. Figure \ref{fig:shadow_dom} shows how shadow DOM trees can be attached to an existing DOM tree.

\begin{figure}[]
    \centering
    \includegraphics[width=\columnwidth]{png/shadow-dom.png}
    \caption{Shadow DOM allows DOM trees (rooted at a \textit{shadow root}) to be attached to the main document tree, providing isolation from external JavaScript. Image source \cite{UsingShadowDOM}}
    \label{fig:shadow_dom}
\end{figure}

We exploited this useful API to encapsulate and hide private data within a shadow DOM. Specifically, we create a closed shadow root, as opposed to an open shadow root which is the default creation mode. This allows us to create a document fragment, or a subtree of the DOM, which cannot be introspected by other JavaScript code running on the same page. This is achieved in client-side JavaScript, by calling \texttt{Element.prototype.attachShadow} method on an existing \texttt{HTMLElement} on the page, as shown in Figure \ref{fig:shadow_root}.

\begin{center}
    \begin{lstlisting}
    const span = document.createElement("span");
    const shadowRoot = span.attachShadow({
        mode: "closed",
    });
    shadowRoot.innerHTML = "Private Data";
    \end{lstlisting}
    \captionof{figure}{Example JavaScript code which attaches a shadow root to a HTML element.}
    \label{fig:shadow_root}
\end{center}

One may wonder if this method is truly secure, as it is also asserted on the Shadow DOM guide \cite{Bidelman} that closed shadow roots may be seen by some as an ``artificial security feature'', since an attacker could trivially overload the \texttt{Element.prototype.attachShadow} method with a malicious implementation using JavaScript code executed on the same page.

To get around this, we execute the JavaScript code that calls \texttt{Element.prototype.attachShadow} within a content script \cite{ContentScript}, a feature of Chrome extensions. Content scripts are injected into the context of the current webpage, but executed in isolated JavaScript environments (known as \textit{Isolated Worlds}). The purpose of Chrome's Isolated Worlds feature allows Chrome extensions to have privileged access to Chrome APIs (such as \texttt{chrome.storage}) that should not be permissible by JavaScript running on the web page.

As such, any changes to the JavaScript environment in the web page would not affect the JavaScript environment within the content script of our browser extension, hence making it immune from \texttt{attachShadow} overloading attacks. Additionally, because of this, the browser extension must be written for a Chromium browser, in order to support the execution of content scripts in isolation from the untrusted web page's JavaScript code.

While this might not be the best approach to secure private data in the same DOM as untrusted JavaScript code, we were unable to find any exploits that can bypass the shadow boundary in our case when using shadow DOM in conjunction with content scripts. Since shadow DOMs were not developed with security in mind, such an approach may not be secure in the long run as browser capabilities and web specifications change over time.

We hope that browsers and web standards committees may one day design an idiomatic approach to isolate content within a DOM from external JavaScript with security in mind. A case in point would be this discussion on the W3C's GitHub issue tracker, which discusses the use case of the \texttt{closed} mode shadow root in the context of security \cite{GitHubW3C}.

\subsection{Keybase-backed private data storage}

We chose to use Keybase \cite{Keybase} as our storage and transport mechanism as it already provides both authenticity and confidentiality guarantees out of the box, as well as other neat features like filesystem abstractions (KBFS) \cite{KBFS} and an end-to-end encrypted message passing mechanism (Keybase Chat) \cite{KeybaseChat}.

KBFS is a network-backed filesystem, which can be mounted on local machines using the Filesystem in Userspace (FUSE) API or accessed via a command-line interface. In particular, it provides the \texttt{/keybase/private} top-level folder (TLF), where all files are both signed (ensuring integrity) and encrypted (ensuring confidentiality), while files in the \texttt{/keybase/public} TLF are only signed by default. This provides the property that all private data, stored in \textit{data files}, will be encrypted at rest, and we can be sure that they have not been tampered with.

Keybase also uses the saltpack \cite{saltpack} message format for encrypting data for multiple users. The message is encrypted using each recipient's private key separately, such that each user would be able to decrypt the message independently using their own key. Furthermore, saltpack allows the public keys of recipients to be hidden in the encrypted message format. We found that this encrypted message format is amenable to storing data files due to the above two properties mentioned.

In the case of Paranoid, we store most metadata in the \texttt{/keybase/private} TLF, including information about services and identities, as well as the generated public/private key pair for an identity. On the other hand, we store data files, which can be shared with other users, in the \texttt{/keybase/public} TLF, encrypted using the keys of all users who have access to them, which does not expose the private values to anyone who does not have access, and also does not expose the set of users which have access to a given data file.

There is actually no real need to store the Paranoid metadata within the private TLF, since we only need to depend on the public TLF for the purposes of sharing encrypted data files. We could instead store the Paranoid metadata within an encrypted database stored on the user's local computer. However, by colocating all Paranoid data within KBFS, it gives us the nice side-effect of allowing Paranoid data to be synchronized over multiple devices and thus allowing a user to seamlessly use Paranoid on multiple devices, as long as each device is authorized to access the same Keybase account.

In order to not expose the list of services and the corresponding UIDs that a Keybase user has registered for, we use a deterministic hash function (specifically, SHA-256) to hash the field tuple as the filename for the data file. This still allows recipients to access the data file in the owner's \texttt{/keybase/public} TLF as long as they keep track of the list of data files that they have access to.

\subsection{Share requests}

KBFS also does not provide a push-like synchronization mechanism (a la Dropbox), but instead clients must pull files on demand. While this still allows a recipient to be aware of any changes to a data file that they had previously been granted access to by pulling the data file again from the owner's public TLF, we need to construct a way to notify the recipient that they have been granted access to a new data file.

\begin{figure}[]
    \centering
    \includegraphics[width=0.8\columnwidth]{png/share_request.png}
    \caption{Example share request dialog that requests the user to confirm whether if a field tuple sent by \texttt{max} on Keybase should be added to the user's foreign map, to allow placeholder replacements for the specified field tuple. In this case, the field tuple is \texttt{(origin="http://127.0.0.1:8000", uid="13", field\_name="first\_name")}.}
    \label{fig:share_request}
\end{figure}

As such, we introduce the notion of a share request. A screenshot of an example share request in the browser can be seen in Figure \ref{fig:share_request}. The owner $A$ chooses to grant access of a data file to a recipient $B$, and as such re-encrypts the data file using $B$'s public key in addition to all previous users' public keys, which immediately allows $B$ to decrypt the data file.

To notify $B$ of a data file that is now made accessible to him, we send a Keybase Chat message originating from $A$ to $B$, of a share request that $A$ wants to send to $B$. $B$ can then accept the share request, which would keep track of the field tuple in its private storage's \textit{foreign map}, and thus allowing the browser extension to now replace tags corresponding to $A$ on the service's web page.

\section{Security Overview}

\subsection{Threat and trust model}

As we have discussed thus far, Paranoid was extensively designed to assume that we cannot trust web services with private data at all for various reasons described in \cref{sec:project_goals}. However, we expect that in order to be compliant with Paranoid, web services must ensure that UIDs assigned to users during registration are unique. After all, we believe that web services are incentivized to ensure that the integrity of their user authentication scheme is not compromised, and only grant users session cookies after sufficient authorization to prove their identity, even if we do not trust that they will not misappropriate personal data.

Since Paranoid's functionality is highly dependent on Chromium extension features, we also have to include the browser (as well as the underlying machine it runs on) as part of the trusted computing base (TCB). Fidelius (2019) \cite{Eskandarian2019} explores various strategies when dealing with user secrets on top of compromised browsers, which could potentially be integrated with Paranoid for those who are \textit{truly paranoid}.

Paranoid assumes that the user trusts all other users that they chose to share their data with via share requests, since the act of re-encrypting a private data file with a new user's public key would immediately grant them read access to the private data, even if they do not accept the share request on their end. Users who have data shared with them may choose to copy out the private data out of KBFS, and Paranoid makes no guarantees that if they later changed their mind and decided to ``unshare'' or rescind the share request, that the other user does not still have a copy of the data. In other words, once shared, we must assume that the values shared to the user is irrevocable. However, it is still possible for the user to rescind the share request, then update the private data to a new value (for example, a password), and the other user would not be able to read the new private value.

Paranoid also assumes that users perform their due diligence to ensure that users who they send share requests to over Keybase are indeed the correct user they wish to send to. After all, the underlying idea of Keybase is to provide cryptographically provable identities, by associating a Keybase user with identities on other sites like Facebook, GitHub and Twitter. Keybase also relies on the concept of ``following'' \cite{KeybaseFollowing}, where Keybase users can sign a snapshot of another user's identity at the time when they have verified their identity with both automatic scraping of proofs and manual verification. We hope that Paranoid users would make use of the tools that Keybase has provided in order to prove another user's identity before sending them a share request.

Finally, Paranoid also places a huge amount of trust in the Keybase and KBFS systems, since all metadata and private data files are stored in KBFS. We have several reasons to believe it to be reasonable to trust Keybase at this time. Firstly, all of Keybase's client source code is open source and available on GitHub, and given the amount of attention it is receiving in recent years, it would be easy to discover security vulnerabilities or malicious code hidden within the Keybase client source. Secondly, Keybase encourages the client to be highly skeptical of the server at any given time, such that any ``rollbacks'' or illegitimate changes to a user signature chain in the Merkle tree can be detected, thus preventing the server from rewriting history should it become compromised \cite{KeybaseServerSecurity}. Finally, Keybase is also riding on the relative infallibility of the Bitcoin blockchain, by publishing its Merkle root (and thus verifying all past Merkle tree entries) into the Bitcoin blockchain every so often \cite{KeybaseBitcoin}, making it even harder for adversaries to compromise user signature chains.

\subsection{Encryption}

We make use of Keybase to provide encryption at rest of all private data files and metadata. One other alternative we considered was to simply store the data within HTML5 \texttt{localStorage} within the browser extension, but we found that it was implemented as an unencrypted database on the filesystem as an IndexedDB file. This database is accessible to all processes on the machine, even after the machine is shut off. On the other hand, all files in KBFS are stored encrypted, and require the user key to decrypt them.

As such, no keys or data files are stored in the browser such that it can be accessible by JavaScript, and instead all secrets must be decrypted and transmitted from the daemon server to the browser extension over HTTPS.

\subsection{Potential attacks}

In this section we describe any potential attacks on Paranoid based on our design described above. We find that the relevant attacks discussed are all reasonably mitigated by our design and implementation, or otherwise have proposed solutions to mitigate them.

\subsubsection{JavaScript Prototype Poisoning}

As described in \cref{sec:shadow_dom}, malicious JavaScript code might poison the prototype function for \texttt{Element.prototype.attachShadow}, overriding it with an implementation that still allows the web page's JavaScript to access the DOM elements despite creating a shadow root. The malicious implementation could simply ignore the \texttt{mode} option in the \texttt{attachShadow} arguments, which makes the resultant shadow root default to an open mode.

However, the use of content scripts in Chrome's \textit{Isolated Worlds} feature \cite{ContentScript} makes the browser extension immune to such prototype poisoning vulnerabilities.

\subsubsection{Cross-Site Request Forgery (CSRF)}

The daemon server sends all data files unencrypted to the browser extension, and thus it is crucial to lockdown access to the daemon server as much as possible. Furthermore, the browser extension has to be able to access the daemon server from the context of any origin, since it operates on the service's web page itself, and thus we have to enable Cross-Origin Resource Sharing (CORS) for all origins on the daemon server (i.e. the server sends the header \texttt{Access-Control-Allow-Origin: *}). This opens up the possibility for the web service to execute malicious JavaScript on the client side, to make unauthorized requests to the daemon server to exfiltrate secrets, such as private keys or private data files, using Cross-Site Request Forgery (CSRF).

While the typical CSRF protection usually involves browser enforcement of CORS or using CSRF tokens, this does not apply in our case, since requests have to be made automatically when a page is loaded for an untrusted origin. We realised the key idea is to perform authentication such that only the browser extension is able to make the request, and not arbitrary JavaScript on the page.

We thus make use of a authorization token to authenticate all HTTPS clients to the daemon server. This authorization token has to be made known to the browser extension before Paranoid is used. The browser extension sends a HTTP `Authorization` header, which the daemon server uses to authenticate all incoming HTTP requests, and reject the request if the authorization token does not match.

This authorization token is stored within the extension's \texttt{localStorage} IndexedDB location, instead of a per-origin \texttt{localStorage}. Although unencrypted, we can ensure that untrusted JavaScript on third-party web pages do not have access to the authorization token to open up the system to CSRF.

\subsubsection{Man-in-the-middle (MITM)}

To prevent MITM attacks, the communication between the browser extension and the daemon server should be encrypted over TLS. This prevents network adversaries from snooping on plaintext private data, or to intercept and modify data that is sent to the browser extension.

Furthermore, we also want to minimize other possible attacks like DNS hijacking, and thus the daemon server's hostname should be resolved locally, preferably within the \texttt{/etc/hosts} file.

\subsubsection{Impersonation attacks}

Using our implementation, it is also possible for a user to impersonate another user's service identity. Suppose Alice is associated with UID 13 on the service \texttt{origin.com}. However, Harry sends Bob a share request claiming to be associated with UID 13, and if Bob accepts the share request, Bob would mistakenly think that user 13 on \texttt{origin.com} is Harry, and thus making Bob think that all content on the service's site associated with UID 13 belongs to Harry.

One may think we could simply use Keybase's mechanism of proofs to resolve this. However, we must remember that identities hidden via Paranoid are \textit{intentionally} made anonymous to the public, which puts it at odds with the goals of Keybase identity proofs. As such, Alice's Keybase user account cannot be publishing a signed identity proof claiming to be UID 13 on \texttt{origin.com}, as this would give away her identity that she wanted to keep secret from the world.

One initially plausible solution would be for the service itself to publish Alice's public key, allowing Bob to prove the Alice's identity by requesting the user to solve a challenge signed with the public key. However, it is also entirely possible for the service to lie about a user's public key, since we do not trust the service.

As such, we see that the only viable solution would be to defer the responsibility of proof to a trusted platform. For example, we could modify the SSO flow such that when Alice registers on a service with her public key and receives a UID of 13, the service must publish this $\langle public\_key, uid \rangle$ association onto a distributed ledger that we all trust. If a user wants to send a share request to Bob claiming to be user 13, Bob can then look up the ledger to retrieve the associated public key with the UID 13, and send the user a challenge encrypted with the associated public key, in order for the user to prove ownership of the user account with UID 13, i.e. whether the user is indeed Alice.

Note that we must use a ledger so that adversaries cannot rewrite previously published associations. We did not implement this in our implementation, but we see how we could easily extend the current implementation to make use of a ledger for proving claims for a UID.

\subsubsection{Side channel attacks}

Since much of Paranoid is implemented as a browser extension that houses private data in plaintext, there is very little the JavaScript extension can do in terms of preventing side channel attacks. Because we must trust the browser, we must also trust the underlying machine to not leak the private user secrets. As such, Paranoid cannot defend against attacks like Spectre \cite{Kocher2018spectre}. We believe this to be reasonable since plaintext secrets should only live on client machines, reducing the attack surface as compared to having secrets accessible to a server accessible to the world over HTTP.

When Paranoid performs the data overlay by attaching a shadow root, it is also possible to leak side-channel information about the encapsulated data that external JavaScript can read. Heiderich et al. \cite{Heiderich:2012:SAS:2382196.2382276} demonstrates a possibility to reliably extract the characters in a string by using custom fonts. Since shadow DOMs inherit CSS styles from its parent, this attack is reasonably easy to exploit by a malicious web service.

It may be possible to mitigate such an attack vector by blacklisting specific CSS properties in the shadow root which might lead to side channel leakage. For example, we could potentially disable all inherited styles in the shadow root like described in Figure \ref{fig:reset_shadow_inherit}.

\begin{figure}
    \begin{lstlisting}
    const shadow = span.attachShadow({
      mode: "closed"
    });
    shadow.innerHTML = `<style>
      :host {
        all: initial;
      }
    </style>`;
    \end{lstlisting}
    \captionof{figure}{Adding an explicit \texttt{all: initial} property would reset all inherited styles from the host element.}
    \label{fig:reset_shadow_inherit}
\end{figure}

\section{Implementation}

Taking into consideration meeting the security goals as outlined, as well as making the user experience for Paranoid as seamless as possible, we designed Paranoid to be packaged as a Chromium extension, which depends on a daemon server, which we wrote in Python.

The source code for Paranoid can be found on GitHub at \url{https://github.com/irvinlim/paranoid}.

\subsection{Browser extension}

The Paranoid browser extension is the user's entry point into Paranoid, where data overlay occurs in the background of every web page, hooks onto the browser to provide SSO, and provides the user a settings web interface to control field mappings and other settings.

We used a custom protocol handler \texttt{web+paranoid://} that has to be registered in the browser on first run of the extension. This protocol handler serves as a well-known origin that Paranoid-compliant web services can redirect to, in order to begin the SSO process. The protocol handler also handles the share request confirmation prompt, as seen in Figure \ref{fig:share_request}.

This protocol handler is registered using the \texttt{Navigator.registerProtocolHandler} API \cite{RegisterProtocolHandler}. The API restricts custom scheme names available to developers to have to begin with \texttt{web+}.

Private data overlay is achieved by attaching a shadow root using content scripts for security reasons, as explained in \cref{sec:shadow_dom}. The script would run on the context of all URLs. Once the page has completed loading, after the DOM tree has been fully parsed, all \texttt{<paranoid>} tags will be inspected and relevant shadow roots will be attached accordingly.

Finally, the extension also provides a user interface. The interface allows for users to change settings, change private data for specific fields as well as share or revoke access to the private data with other users completely within the browser. This was designed with the user in mind, since it would be infeasible to ask the user to maintain a bunch of JSON files on their own. Figure \ref{fig:settings} provides an example screenshot.

\begin{figure}[]
    \centering
    \includegraphics[width=\columnwidth]{png/settings.png}
    \caption{User interface to manage Paranoid settings.}
    \label{fig:settings}
\end{figure}

\subsection{Daemon server}

The daemon is a simple application that bridges that gap between the Paranoid extension and keybase. The daemon essentially acts as a relay between them. While the daemon is simple in theory, implementing it was trickier than expected.

We faced several problems ensuring cross-platform compatibility between Unix and Windows. For example, on Unix the KBFS mount point is \texttt{/keybase}, while in Windows it is the \texttt{K:} drive. Differences in directory separators led us to execute all KBFS queries using the \texttt{keybase} command-line executable, rather than direct filesystem calls, but there were still several nuanced differences between the clients on Windows and Unix.

Additionally, since Windows does not allow the colon (\texttt{:}) character in filenames, which we used to identify origins uniquely (in the format \texttt{<scheme>:<hostname>:<port>}), we had to perform substring replacement to convert colons into \texttt{@} characters instead, which is not a valid character in an origin and thus was a viable candidate for substitution.

The initial build of the daemon was quickly found to be taking over 2 seconds to respond to a simple \texttt{GET} request from the extension via AJAX. Since we are storing all data on KBFS, a request may require many \texttt{read(2)} and \texttt{getdents(2)} calls of several different files and directories within KBFS. Considering that the private TLF is fully encrypted, and data files in the public TLF are also encrypted, much of the overhead may stem from the fact that we have to repeatedly perform decryption of not only data files, but every single filesystem data structure in KBFS while traversing the path.

As such, a caching mechanism became a necessity and we managed to improve the response time of the daemon server by implementing an in-memory cache that stores all decrypted metadata and data files, and updating the cache only when an update is made.

\subsection{Sample Paranoid-compliant web service}

As part of our testing efforts, we created a simple sample Paranoid web service that deploys the Paranoid SSO and displays a placard for each user registered. Each placard contains Paranoid placeholders for users' first name, email and bio. The service also hosts a field map in JSON format (Figure \ref{fig:paranoid_map}) that contains all the field names required by the service. This JSON file is consumed during the SSO process such that the daemon can create the relevant field entries. Subsequently, users can use the user interface to change the default field entry values.

\begin{figure}
    \begin{lstlisting}
{
    "placeholders": ["first_name", "last_name", "email", "image", "bio"],
    "last_updated": 1574027849888
}
    \end{lstlisting}
    \captionof{figure}{Example field map, accessible at \texttt{origin.com/paranoid\_map} on the web service.}
    \label{fig:paranoid_map}
\end{figure}

\section{Evaluation}

\subsection{Performance evaluation}

Quantitative performance evaluation was only performed on our sample web service that we developed. Since Paranoid requires web services to integrate with our SSO mechanism as well as to explicitly return \texttt{<paranoid>} tags in place of private data, we could not integrate with any production web services readily.

Paranoid demonstrated little to no overhead to the client host system as well as web page loading times. Placeholder overlays similarly saw little to no performance overhead but displayed a visual delay of 500ms-1000ms before private data shows up on the page. This mainly due to the fact that overlay operations only execute after a page has completed loading, hence, users may see partially-rendered pages with placeholders values. However, this sub-second visual delay is a step up from the previous >3000ms delays we used to see before implementing the caching system in the daemon. With caching integrated, in one of our tests, the response for a particular endpoint to return a single service identity's metadata and data files saw a ~130x improvement (3703ms uncached vs 27ms cached), drastically reducing visual delay.

\subsection{Security evaluation}

We also developed an ``evil'' page (accessible via \texttt{/evil}) within the sample application, in order to simulate a malicious service attempting to siphon user's private data. The malicious script run on the ``evil'' page would in theory, attempt to:

\begin{enumerate}
    \item Wait 5000 ms for Paranoid data overlay to take place, such that private data is now in the DOM.
    \item Query for elements containing \texttt{<paranoid>} tags and get the \texttt{outerHTML} of the entire DOM subtree.
    \item Send the \texttt{outerHTML} as a string back to the malicious server via an AJAX request.
\end{enumerate}

Since we are using a closed shadow root, this prevents the JavaScript interpreter from accessing the private data inside of the shadow DOM subtree without having an explicit reference to the shadow root itself.

We also attempted to override the \texttt{Element.prototype.attachShadow} method via a malicious script that was run in the context of the web page. This had no effect, due to the Isolated Worlds capability of content scripts in Chrome.

\subsection{Limitations}

After the initial page load and data overlay process, our implementation would fail to replace any \texttt{<paranoid>} elements that are subsequently added to the DOM, which is an increasing pattern used in JavaScript frameworks like React. However, it should be trivial to monitor changes to the DOM and attach shadow roots accordingly by using the \texttt{MutationObserver} API, and perform DOM updates only on parts of the DOM which were modified.

Our implementation also cannot handle non-HTML data overlays. This might include private data placeholders that are supposed to be replaced in non-HTML elements, such as browser alerts, console messages, or URL parameters. Since we are relying extensively on the shadow DOM API to provide isolation from the untrusted web service, Paranoid does not provide a mechanism to support these use cases should they arise in a web service.

Our design also necessitates the web service, which we do not trust, to follow a certain API in terms of supporting SSO and data overlays. This might slow down adoption of Paranoid by the public since it would explicitly require services to opt-in. However, we believe that the simple integration requirements on the part of the service, coupled with increasing pressure from the public for organizations to provide better data protection of personal data, would allow for Paranoid's design to be easily adopted by services in the near future.

\section{Related Work}

Various work has been done to design a system that allows for user-to-user encryption atop untrusted web services in the past. Notably, we discovered (rather late in our project) that there has been quite a number of attempts in designing such systems using shadow DOMs specifically, including others who have openly found vulnerabilities with their approach. We will discuss these past works, how Paranoid compares with them (including how it fares in terms of previous security concerns raised), as well as how other solutions might work better.

Perhaps the earliest known attempt to separate private data from web services is Priv.ly \cite{Privly}, which uses hyperlinks to identify private data embedded on a web page, which can be downloaded from a distributed storage host network, before being decrypted in the browser with an extension. This approach uses \texttt{iframe}s to overlay private data into the page, which provides isolation but effectively does not allow the web service to define the appearance of the rendered content, unlike Paranoid. Additionally, using \texttt{iframe}s provide greater security and isolation than shadow DOM elements, considering that Chromium has moved them to separate processes with the introduction of out-of-process \texttt{iframe}s \cite{OOPIFs}, but at the same time would tend to have a much more significant performance overhead on a page with hundreds of such \texttt{iframe}s.

Mylar \cite{Popa:2014:BWA:2616448.2616464} explores this problem in a similar but opposite approach; it introduces a platform for designing web services to be resistant against data confidentiality attacks for its users at various levels. Mylar explores an approach where all user data is stored encrypted in the remote server, and only decrypted in the browser since keys are only stored locally on the client. This is similar to the approach that Paranoid has taken to store private data on a separate data plane from application code.

We also discovered previous work by He et al. \cite{He:2014:SEW:2660267.2660326} on ShadowCrypt (2014), which is very similar in concept to Paranoid. ShadowCrypt relies on the Shadow DOM v0 specification, together with explicit patching of the several attributes and methods (\texttt{Element.shadowRoot}, \texttt{Element.olderShadowRoot}, \texttt{Element.getDistributedNodes()}), to encapsulate plaintext private user data in the DOM, much like what Paranoid does. In addition, ShadowCrypt attaches shadow roots to input fields, providing an encapsulated input field for the user to enter their information, which should be isolated from the main web page's JavaScript code.

Recent work by Freyberger et al. \cite{Freyberger2018} also demonstrates several attacks against ShadowCrypt. The most severe exploit is a user interface attack, which directly fools the user into thinking they are entering private data into an encrypted field encapsulated with ShadowCrypt; however malicious third-party JavaScript and CSS could be used to mimic the appearance of a ``secure'' input field used in ShadowCrypt. Paranoid does not suffer from this security problem, since all user data is entered on the extension's settings page, which cannot be compromised remotely by a third-party web service since all code is client-side.

Freyberger et al. also discusses the fragility of relying on the Shadow DOM API for isolation, which was at version 0 when implemented in ShadowCrypt; it is currently at version 1 with a completely different API. Because of frequent changes to the unstable web specification, ShadowCrypt remained vulnerable to new features that were released by Chrome, including newer CSS selectors like \texttt{::shadow} and \texttt{body /deep/ span} which allowed untrusted JavaScript to cross the shadow boundary. On the other hand, Paranoid remains unfettered against these exploits, presumably because of the new \texttt{closed} mode which was added in the version 1 specification of the shadow DOM.

However, we would never know if Paranoid would be able to stand against the test of time, since what happened to ShadowCrypt could very well happen to Paranoid as well. Freyberger et al. brings up a very good point that until a fundamental browser primitive is designed for such a purpose, systems like ShadowCrypt and Paranoid may always remain fragile and at risk of data exposure by relying on non-standard functionality for the purposes of security.

\section{Conclusions}

Paranoid explores a novel approach by moving away from traditional modes of communications and interactions between users and services. Paranoid demonstrates effectiveness at and the value of keep private data secure and out of the hands of services. Paranoid further demonstrates the enablement of users to regain control of their personal data, through a seamless and user-friendly approach. Paranoid achieves the goals set out in its objectives at the cost of little to no overhead to both the users and web services.

%-------------------------------------------------------------------------------

\bibliography{bibliography}
\bibliographystyle{acm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%  LocalWords:  endnotes includegraphics fread ptr nobj noindent
%%  LocalWords:  pdflatex acks
